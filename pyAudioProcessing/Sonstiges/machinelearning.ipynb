{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufnahme der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainieren und Klassifizieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "--------------------------------------------------\nBitte drehen Sie jetzt nach rechts!\n--------------------------------------------------\nRecording 1\nFinished recording 1\nRecording 2\nFinished recording 2\nRecording 3\nFinished recording 3\nRecording 4\nFinished recording 4\nRecording 5\nFinished recording 5\nRecording 6\nFinished recording 6\nRecording 7\nFinished recording 7\nRecording 8\nFinished recording 8\nRecording 9\nFinished recording 9\nRecording 10\nFinished recording 10\n--------------------------------------------------\nBitte aufhören zu drehen!\n--------------------------------------------------\n--------------------------------------------------\nBitte drehen Sie jetzt nach links!\n--------------------------------------------------\nRecording 11\nFinished recording 11\nRecording 12\nFinished recording 12\nRecording 13\nFinished recording 13\nRecording 14\nFinished recording 14\nRecording 15\nFinished recording 15\nRecording 16\nFinished recording 16\nRecording 17\nFinished recording 17\nRecording 18\nFinished recording 18\nRecording 19\nFinished recording 19\nRecording 20\nFinished recording 20\n--------------------------------------------------\nBitte aufhören zu drehen!\n--------------------------------------------------\n"
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "for x in range(1,21):\n",
    "    if x is 1:\n",
    "        time.sleep(3)\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(\"Bitte drehen Sie jetzt nach rechts!\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        time.sleep(5)\n",
    "    if x is 11:\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(\"Bitte aufhören zu drehen!\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        time.sleep(3)\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(\"Bitte drehen Sie jetzt nach links!\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        time.sleep(5)\n",
    "    if x in [1,10]:\n",
    "        o=\"rechts\"\n",
    "    if x in [11,20]:\n",
    "        o=\"links\"  \n",
    "    #chunk = 1024  # Record in chunks of 1024 samples\n",
    "    chunk = 100\n",
    "    sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "    channels = 1\n",
    "    fs = 44100  # Record at 44100 samples per second\n",
    "    seconds = 10\n",
    "    filename = (\"data_samples/training/none/lttl\"+str(x)+\".wav\")\n",
    "\n",
    "    p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "    print('Recording '+str(x))\n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=fs,\n",
    "                    frames_per_buffer=chunk,\n",
    "                    input=True)\n",
    "    frames = []  # Initialize array to store frames\n",
    "    # Store data in chunks for 3 seconds\n",
    "    for i in range(0, int(fs / chunk * seconds)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "    # Stop and close the stream \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    # Terminate the PortAudio interface\n",
    "    p.terminate()\n",
    "    print('Finished recording ' + str(x))\n",
    "    # Save the recorded data as a WAV file\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "    wf.setframerate(fs)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    time.sleep(1)\n",
    "    if x is 20:\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(\"Bitte aufhören zu drehen!\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training: Support Vektor machine "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioProcessing.run_classification import train_and_classify\n",
    "# Training \n",
    "#train_and_classify(\"data_samples/training\", \"train\", [\"gfcc,mfcc\"], \"svm\", \"svm_clf\")\n",
    "#train_and_classify(\"data_samples/training\", \"train\", [\"gfcc\"], \"svm\", \"svm_clf\")\n",
    "train_and_classify(\"data_samples/training\", \"train\", [\"gfcc,mfcc\"], \"svm\", \"svm_clf\")\n",
    "#train_and_classify(\"data_samples/training\", \"train\", [\"gfcc,mfcc\"], \"randomforest\", \"svm_clf\")\n",
    "#train_and_classify(\"data_samples/training\", \"train\", [\"gfcc\"], \"svm\", \"svm_clf\")\n",
    "#train_and_classify(\"data_samples/training\", \"train\", [\"gfcc,mfcc\"], \"svm\", \"svm_clf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "          "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "\n",
    "#chunk = 1024  # Record in chunks of 1024 samples\n",
    "chunk = 1024\n",
    "sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "channels = 1\n",
    "fs = 44100  # Record at 44100 samples per second\n",
    "seconds = 10\n",
    "filename = (\"data_samples/testing/test/test.wav\")\n",
    "\n",
    "for i in range(0,1):\n",
    "    p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "    print(\"Recording Test\")\n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=fs,\n",
    "                    frames_per_buffer=chunk,\n",
    "                    input=True)\n",
    "    frames = []  # Initialize array to store frames\n",
    "    # Store data in chunks for 3 seconds\n",
    "    for i in range(0, int(fs / chunk * seconds)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "    # Stop and close the stream \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    # Terminate the PortAudio interface\n",
    "    p.terminate()\n",
    "    print(\"Finished recording Test\")\n",
    "    # Save the recorded data as a WAV file\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "    wf.setframerate(fs)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    time.sleep(1)\n",
    "        \n",
    "    # Classify data\n",
    "    from pyAudioProcessing.run_classification import train_and_classify\n",
    "\n",
    "    train_and_classify(\"data_samples/testing\", \"classify\", [\"gfcc,mfcc\"], \"svm\", \"svm_clf\")\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    import json\n",
    "    from pprint import pprint\n",
    "\n",
    "    with open('classifier_results.json') as f:\n",
    "        data = json.load(f)\n",
    "    Klasse1 =(data[\"data_samples/testing\\\\test\"][\"test.wav\"][\"classes\"][0])\n",
    "    Wert1= (data[\"data_samples/testing\\\\test\"][\"test.wav\"][\"probabilities\"][0])\n",
    "    Klasse2= (data[\"data_samples/testing\\\\test\"][\"test.wav\"][\"classes\"][1])\n",
    "    Wert2= (data[\"data_samples/testing\\\\test\"][\"test.wav\"][\"probabilities\"][1])\n",
    "    print(\"###############################Ergebnis#####################################################\")\n",
    "    #print(str(Klasse1) + \":\" + str(Wert1)) #links\n",
    "    #print(str(Klasse2) + \":\" + str(Wert2)) #rechts\n",
    "    if Wert1>Wert2:\n",
    "        print(\"Die Drehrichtung ist \"+str(Klasse1)+\", mit dem Wahrscheinlickeit von \"+str(Wert1))\n",
    "    if Wert1<Wert2:\n",
    "        print(\"Die Drehrichtung ist \"+str(Klasse2)+\", mit dem Wahrscheinlickeit von \"+str(Wert2))\n",
    "    if Wert1==Wert2:\n",
    "        print(\"Fehler\")\n",
    "    print(\"############################################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioProcessing.run_classification import train_and_classify\n",
    "import time\n",
    "train_and_classify(\"data_samples/testing\", \"classify\", [\"gfcc,mfcc\"], \"svm\", \"svm_clf\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('classifier_results.json') as f:\n",
    "    data = json.load(f)\n",
    "Klasse1 =(data[\"data_samples/testing\\\\test\"][\"test.wav\"][\"classes\"][0])\n",
    "Wert1= (data[\"data_samples/testing\\\\test\"][\"test.wav\"][\"probabilities\"][0])\n",
    "Klasse2= (data[\"data_samples/testing\\\\test\"][\"test.wav\"][\"classes\"][1])\n",
    "Wert2= (data[\"data_samples/testing\\\\test\"][\"test.wav\"][\"probabilities\"][1])\n",
    "Klasse3=(data[\"data_samples/testing\\\\test\"][\"test.wav\"][\"classes\"][2])\n",
    "Wert3= (data[\"data_samples/testing\\\\test\"][\"test.wav\"][\"probabilities\"][2])\n",
    "print(\"###############################Ergebnis#####################################################\")\n",
    "#print(str(Klasse1) + \":\" + str(Wert1)) #links\n",
    "#print(str(Klasse2) + \":\" + str(Wert2)) #rechts\n",
    "if Wert1>Wert2 , Wert1>Wert3:\n",
    "    print(\"Die Drehrichtung ist \"+str(Klasse1)+\", mit dem Wahrscheinlickeit von \"+str(Wert1))\n",
    "if Wert1<Wert2 , Wert2>Wert3:\n",
    "    print(\"Die Drehrichtung ist \"+str(Klasse2)+\", mit dem Wahrscheinlickeit von \"+str(Wert2))\n",
    "if Wert3>Wert1 , Wert3>Wert2:\n",
    "    print(\"Die Drehrichtung ist \"+str(Klasse3)+\", mit dem Wahrscheinlickeit von \"+str(Wert3))\n",
    "if Wert1==Wert2:\n",
    "    print(\"Fehler\")\n",
    "print(\"############################################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Object `python audioAnalysis.py fileSpectrogram  ./data_samples/training/rechts/ll1.wav` not found.\n"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}